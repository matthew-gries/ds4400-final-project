{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xdUwwSY_vCp0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "from ds4400_final_project.dataset.constants import DATASET_FOLDER\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_from_file(csv_filename: str) -> Tuple[np.array, np.array, Dict[int, str], Dict[str, int]]:\n",
        "\t\"\"\" Load the CSV file from the dataset folder. \"\"\"\n",
        "\tfile = str(Path(DATASET_FOLDER) / csv_filename)\n",
        "\tfeatures_list = np.genfromtxt(file, dtype=None, encoding=None, delimiter=\",\", skip_header=1, usecols=range(2, 60))\n",
        "\tfeatures = np.array([list(x) for x in features_list])\n",
        "\n",
        "\t# Create a mapping between a numeric value and genre\n",
        "\tindex_genre_map = {i: genre for i, genre in enumerate(np.unique(features[:,-1]))}\n",
        "\tgenre_index_map = {value: key for key, value in index_genre_map.items()}\n",
        "\n",
        "\t# split the inputs and their labels\n",
        "\tx = features[:,:57]\n",
        "\ty = np.array([genre_index_map[genre] for genre in features[:,-1]])\n",
        "\n",
        "\treturn x, y, index_genre_map, genre_index_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import the data from the 3 seconds features CSV\n",
        "X, y, index_genre_map, genre_index_map = load_data_from_file(\"features_3_sec.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = normalize(X, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.00860081,  0.01066405,  0.00883209, ...,  0.00487959,\n",
              "        -0.00045597,  0.00593612],\n",
              "       [ 0.00879721,  0.01008993,  0.00763291, ...,  0.0140838 ,\n",
              "         0.0108522 ,  0.0081292 ],\n",
              "       [ 0.00889336,  0.01080397,  0.00894034, ...,  0.00770021,\n",
              "         0.00472316,  0.00448956],\n",
              "       ...,\n",
              "       [ 0.00891044,  0.01042643,  0.00354915, ...,  0.00705162,\n",
              "        -0.00056201,  0.00563983],\n",
              "       [ 0.00993735,  0.00993403,  0.00449917, ...,  0.00360599,\n",
              "         0.001268  ,  0.00173422],\n",
              "       [ 0.00946976,  0.01016163,  0.0034219 , ...,  0.00573129,\n",
              "        -0.00640268,  0.00430273]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split all the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = svm.SVC()\n",
        "classifier.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8871871871871871"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.score(X, y)\n",
        "# classifier.score(x_train, y_train)\n",
        "# classifier.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMTBcnr5bDrP6pBPRTXnSCt",
      "include_colab_link": true,
      "name": "test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
